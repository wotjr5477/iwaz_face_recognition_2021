{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8203e5-d7d0-4422-ae67-a961b244cb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd70fe8-996e-432a-929a-eef62856d8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0415d083-38b9-4f2e-9652-cdeb3a0d1da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\CPB06GameN\\\\Python\\\\face_recognition'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db26c8-22de-49e3-860b-2ad3a020a11e",
   "metadata": {},
   "source": [
    "# face_landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0dbca3-bb72-4540-97d3-8497e12b22d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n",
      "=== Detection took 0.724 seconds\n",
      "=== A frame took 0.005 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "RIGHT_EYE = list(range(36, 42))\n",
    "LEFT_EYE = list(range(42, 48))\n",
    "MOUTH = list(range(48, 68))\n",
    "NOSE = list(range(27, 36))\n",
    "EYEBROWS = list(range(17, 27))\n",
    "JAWLINE = list(range(1, 17))\n",
    "ALL = list(range(0, 68))\n",
    "EYES = list(range(36, 48))\n",
    "\n",
    "predictor_file = 'model/shape_predictor_68_face_landmarks.dat'\n",
    "image_file = 'dataset/UZ/11.jpg'\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_file)\n",
    "\n",
    "image = cv2.imread(image_file)\n",
    "image_resize = cv2.resize(image, dsize=(700,700), interpolation = cv2.INTER_AREA) #사이즈 수정\n",
    "gray = cv2.cvtColor(image_resize, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "start_time = time.time()\n",
    "rects = detector(gray, 2) # 5>시간오래 걸리고 과탐지\n",
    "end_time = time.time()\n",
    "detect_time = end_time - start_time\n",
    "print(\"Number of faces detected: {}\".format(len(rects)))\n",
    "print(\"=== Detection took {:.3f} seconds\".format(detect_time))\n",
    "\n",
    "for (i, rect) in enumerate(rects):\n",
    "    start_time = time.time()\n",
    "\n",
    "    points = np.matrix([[p.x, p.y] for p in predictor(gray, rect).parts()])\n",
    "    show_parts = points[ALL]\n",
    "    for (i, point) in enumerate(show_parts):\n",
    "        x = point[0,0]\n",
    "        y = point[0,1]\n",
    "        #cv2.circle(image, (x, y), 1, (0, 255, 255), -1)\n",
    "        cv2.circle(image_resize, (x, y), 1, (0, 255, 255), -1)\n",
    "        #cv2.putText(image, \"{}\".format(i + 1), (x, y - 2),\n",
    "\t\t#cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1)\n",
    "        cv2.putText(image_resize, \"{}\".format(i + 1), (x, y - 2),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1)\n",
    "    end_time = time.time()\n",
    "    process_time = end_time - start_time\n",
    "    print(\"=== A frame took {:.3f} seconds\".format(process_time))\n",
    "\n",
    "cv2.imshow(\"Face Landmark\", image_resize)\n",
    "cv2.waitKey(0)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847f238-e751-4cc8-bfbc-5ab26f7a4c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abaef1e-1235-4872-a5e5-cfdc12377900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "RIGHT_EYE = list(range(36, 42))\n",
    "LEFT_EYE = list(range(42, 48))\n",
    "EYES = list(range(36, 48))\n",
    "\n",
    "predictor_file = 'model/shape_predictor_68_face_landmarks.dat'\n",
    "image_file = 'dataset/JB/12.jpg'\n",
    "MARGIN_RATIO = 1.5\n",
    "OUTPUT_SIZE = (300, 300)\n",
    "\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_file)\n",
    "\n",
    "image = cv2.imread(image_file)\n",
    "image_resize = cv2.resize(image, dsize=(700,700), interpolation = cv2.INTER_AREA) #사이즈 수정\n",
    "image_origin = image_resize.copy()\n",
    "\n",
    "(image_height, image_width) = image_resize.shape[:2]\n",
    "gray = cv2.cvtColor(image_resize, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "rects = detector(gray, 1)\n",
    "\n",
    "def getFaceDimension(rect):\n",
    "    return (rect.left(), rect.top(), rect.right() - rect.left(), rect.bottom() - rect.top())\n",
    "\n",
    "def getCropDimension(rect, center):\n",
    "    width = (rect.right() - rect.left())\n",
    "    half_width = width // 2\n",
    "    (centerX, centerY) = center\n",
    "    startX = centerX - half_width\n",
    "    endX = centerX + half_width\n",
    "    startY = rect.top()\n",
    "    endY = rect.bottom() \n",
    "    return (startX, endX, startY, endY)    \n",
    "\n",
    "for (i, rect) in enumerate(rects):\n",
    "    (x, y, w, h) = getFaceDimension(rect)\n",
    "    cv2.rectangle(image_resize, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    points = np.matrix([[p.x, p.y] for p in predictor(gray, rect).parts()])\n",
    "    show_parts = points[EYES]\n",
    "\n",
    "    right_eye_center = np.mean(points[RIGHT_EYE], axis = 0).astype(\"int\")\n",
    "    left_eye_center = np.mean(points[LEFT_EYE], axis = 0).astype(\"int\")\n",
    "    print(right_eye_center, left_eye_center)\n",
    " \n",
    "    cv2.circle(image_resize, (right_eye_center[0,0], right_eye_center[0,1]), 5, (0, 0, 255), -1)\n",
    "    cv2.circle(image_resize, (left_eye_center[0,0], left_eye_center[0,1]), 5, (0, 0, 255), -1)\n",
    "    \n",
    "    cv2.circle(image_resize, (left_eye_center[0,0], right_eye_center[0,1]), 5, (0, 255, 0), -1)\n",
    "    \n",
    "    cv2.line(image_resize, (right_eye_center[0,0], right_eye_center[0,1]),\n",
    "             (left_eye_center[0,0], left_eye_center[0,1]), (0, 255, 0), 2)\n",
    "    cv2.line(image_resize, (right_eye_center[0,0], right_eye_center[0,1]),\n",
    "         (left_eye_center[0,0], right_eye_center[0,1]), (0, 255, 0), 1)\n",
    "    cv2.line(image_resize, (left_eye_center[0,0], right_eye_center[0,1]),\n",
    "         (left_eye_center[0,0], left_eye_center[0,1]), (0, 255, 0), 1)\n",
    "\n",
    "    eye_delta_x = right_eye_center[0,0] - left_eye_center[0,0]\n",
    "    eye_delta_y = right_eye_center[0,1] - left_eye_center[0,1]\n",
    "    degree = np.degrees(np.arctan2(eye_delta_y,eye_delta_x)) - 180\n",
    "\n",
    "    eye_distance = np.sqrt((eye_delta_x ** 2) + (eye_delta_y ** 2))\n",
    "    aligned_eye_distance = left_eye_center[0,0] - right_eye_center[0,0]\n",
    "    scale = aligned_eye_distance / eye_distance\n",
    "\n",
    "    eyes_center = ((left_eye_center[0,0] + right_eye_center[0,0]) // 2,\n",
    "            (left_eye_center[0,1] + right_eye_center[0,1]) // 2)\n",
    "    cv2.circle(image_resize, eyes_center, 5, (255, 0, 0), -1)\n",
    "            \n",
    "    metrix = cv2.getRotationMatrix2D(eyes_center, degree, scale)\n",
    "    cv2.putText(image_resize, \"{:.5f}\".format(degree), (right_eye_center[0,0], right_eye_center[0,1] + 20),\n",
    "     \t cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    warped = cv2.warpAffine(image_origin, metrix, (image_width, image_height),\n",
    "        flags=cv2.INTER_CUBIC)\n",
    "    \n",
    "    cv2.imshow(\"warpAffine\", warped)\n",
    "    (startX, endX, startY, endY) = getCropDimension(rect, eyes_center)\n",
    "    croped = warped[startY:endY, startX:endX]\n",
    "    output = cv2.resize(croped, OUTPUT_SIZE)\n",
    "    cv2.imshow(\"output\", output)\n",
    "    \n",
    "    output_file = \"roi/1_out.jpg\"\n",
    "    cv2.imwrite(output_file, output)\n",
    "    \n",
    "    for (i, point) in enumerate(show_parts):\n",
    "        x = point[0,0]\n",
    "        y = point[0,1]\n",
    "        cv2.circle(image, (x, y), 1, (0, 255, 255), -1)\n",
    "\n",
    "cv2.imshow(\"Face Alignment\", image)\n",
    "\n",
    "cv2.waitKey(0)   \n",
    "cv2.destroyAllWindows()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9c4ec-a95f-44a4-b250-8c59d32356f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6d9288-c63f-431e-9947-c19c04d2846d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e6f0a41adffe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m                     (left_eye_center[0,1] + right_eye_center[0,1]) // 2)\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mmetrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetRotationMatrix2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meyes_center\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             warped = cv2.warpAffine(image_origin, metrix, (image_width, image_height),\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'tuple'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "RIGHT_EYE = list(range(36, 42))\n",
    "LEFT_EYE = list(range(42, 48))\n",
    "EYES = list(range(36, 48))\n",
    "\n",
    "dataset_paths = ['./dataset/JB/', './dataset/son', './dataset/tedy']\n",
    "output_paths = ['./dataset/JB_aligned/', './dataset/son_aligned/', './dataset/tedy-aligned/']\n",
    "number_images = 10\n",
    "image_type = '.jpg'\n",
    "\n",
    "predictor_file = './model/shape_predictor_68_face_landmarks.dat'\n",
    "MARGIN_RATIO = 1.5\n",
    "OUTPUT_SIZE = (300, 300)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_file)\n",
    "\n",
    "def getFaceDimension(rect):\n",
    "    return (rect.left(), rect.top(), rect.right() - rect.left(), rect.bottom() - rect.top())\n",
    "\n",
    "def getCropDimension(rect, center):\n",
    "    width = (rect.right() - rect.left())\n",
    "    half_width = width // 2\n",
    "    (centerX, centerY) = center\n",
    "    startX = centerX - half_width\n",
    "    endX = centerX + half_width\n",
    "    startY = rect.top()\n",
    "    endY = rect.bottom() \n",
    "    return (startX, endX, startY, endY)    \n",
    "\n",
    "for (i, dataset_path) in enumerate(dataset_paths):\n",
    "    output_path = output_paths[i]\n",
    "    \n",
    "    for idx in range(number_images):\n",
    "        input_file = dataset_path + str(idx+1) + image_type\n",
    "\n",
    "        # get RGB image from BGR, OpenCV format\n",
    "        image = cv2.imread(input_file)\n",
    "        image_origin = image.copy()\n",
    "\n",
    "        (image_height, image_width) = image.shape[:2]\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        rects = detector(gray, 2)\n",
    "  \n",
    "        for (i, rect) in enumerate(rects):\n",
    "            (x, y, w, h) = getFaceDimension(rect)\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            points = np.matrix([[p.x, p.y] for p in predictor(gray, rect).parts()])\n",
    "            show_parts = points[EYES]\n",
    "\n",
    "            right_eye_center = np.mean(points[RIGHT_EYE], axis = 0).astype(\"int\")\n",
    "            left_eye_center = np.mean(points[LEFT_EYE], axis = 0).astype(\"int\")\n",
    "\n",
    "            eye_delta_x = right_eye_center[0,0] - left_eye_center[0,0]\n",
    "            eye_delta_y = right_eye_center[0,1] - left_eye_center[0,1]\n",
    "            degree = np.degrees(np.arctan2(eye_delta_y,eye_delta_x)) - 180\n",
    "            #degree.astype(\"int\")\n",
    "\n",
    "            eye_distance = np.sqrt((eye_delta_x ** 2) + (eye_delta_y ** 2))\n",
    "            aligned_eye_distance = left_eye_center[0,0] - right_eye_center[0,0]\n",
    "            scale = aligned_eye_distance / eye_distance\n",
    "            #scale = scale.astype(\"int\")\n",
    "\n",
    "            eyes_center = ((left_eye_center[0,0] + right_eye_center[0,0]) // 2,\n",
    "                    (left_eye_center[0,1] + right_eye_center[0,1]) // 2)\n",
    "                    \n",
    "            metrix = cv2.getRotationMatrix2D(eyes_center, degree, scale)\n",
    "\n",
    "            warped = cv2.warpAffine(image_origin, metrix, (image_width, image_height),\n",
    "                flags=cv2.INTER_CUBIC)\n",
    "\n",
    "            (startX, endX, startY, endY) = getCropDimension(rect, eyes_center)\n",
    "\n",
    "            croped = warped[startY:endY, startX:endX]\n",
    "            output = cv2.resize(croped, OUTPUT_SIZE)\n",
    "            #output = warped[startY:endY, startX:endX]\n",
    "            \n",
    "            output_file = output_path + str(idx+1) + image_type\n",
    "            cv2.imshow(output_file, output)\n",
    "            cv2.imwrite(output_file, output)\n",
    "        \n",
    "cv2.waitKey(0)   \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "347f11c3-dc81-41cf-b73a-3122f519779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "RIGHT_EYE = list(range(36, 42))\n",
    "LEFT_EYE = list(range(42, 48))\n",
    "EYES = list(range(36, 48))\n",
    "\n",
    "predictor_file = './model/shape_predictor_68_face_landmarks.dat'\n",
    "image_file = './dataset/JB/12.jpg'\n",
    "MARGIN_RATIO = 1.5\n",
    "OUTPUT_SIZE = (300, 300)\n",
    "\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_file)\n",
    "\n",
    "image = cv2.imread(image_file)\n",
    "image_origin = image.copy()\n",
    "\n",
    "(image_height, image_width) = image.shape[:2]\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "rects = detector(gray, 2)\n",
    "\n",
    "def getFaceDimension(rect):\n",
    "    return (rect.left(), rect.top(), rect.right() - rect.left(), rect.bottom() - rect.top())\n",
    "\n",
    "def getCropDimension(rect, center):\n",
    "    width = (rect.right() - rect.left())\n",
    "    half_width = width // 2\n",
    "    (centerX, centerY) = center\n",
    "    startX = centerX - half_width\n",
    "    endX = centerX + half_width\n",
    "    startY = rect.top()\n",
    "    endY = rect.bottom() \n",
    "    return (startX, endX, startY, endY)    \n",
    "\n",
    "for (i, rect) in enumerate(rects):\n",
    "    (x, y, w, h) = getFaceDimension(rect)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    points = np.matrix([[p.x, p.y] for p in predictor(gray, rect).parts()])\n",
    "    show_parts = points[EYES]\n",
    "\n",
    "    right_eye_center = np.mean(points[RIGHT_EYE], axis = 0).astype(\"int\")\n",
    "    left_eye_center = np.mean(points[LEFT_EYE], axis = 0).astype(\"int\")\n",
    "    print(right_eye_center, left_eye_center)\n",
    " \n",
    "    cv2.circle(image, (right_eye_center[0,0], right_eye_center[0,1]), 5, (0, 0, 255), -1)\n",
    "    cv2.circle(image, (left_eye_center[0,0], left_eye_center[0,1]), 5, (0, 0, 255), -1)\n",
    "    \n",
    "    cv2.circle(image, (left_eye_center[0,0], right_eye_center[0,1]), 5, (0, 255, 0), -1)\n",
    "    \n",
    "    cv2.line(image, (right_eye_center[0,0], right_eye_center[0,1]),\n",
    "             (left_eye_center[0,0], left_eye_center[0,1]), (0, 255, 0), 2)\n",
    "    cv2.line(image, (right_eye_center[0,0], right_eye_center[0,1]),\n",
    "         (left_eye_center[0,0], right_eye_center[0,1]), (0, 255, 0), 1)\n",
    "    cv2.line(image, (left_eye_center[0,0], right_eye_center[0,1]),\n",
    "         (left_eye_center[0,0], left_eye_center[0,1]), (0, 255, 0), 1)\n",
    "\n",
    "    eye_delta_x = right_eye_center[0,0] - left_eye_center[0,0]\n",
    "    eye_delta_y = right_eye_center[0,1] - left_eye_center[0,1]\n",
    "    degree = np.degrees(np.arctan2(eye_delta_y,eye_delta_x)) - 180\n",
    "\n",
    "    eye_distance = np.sqrt((eye_delta_x ** 2) + (eye_delta_y ** 2))\n",
    "    aligned_eye_distance = left_eye_center[0,0] - right_eye_center[0,0]\n",
    "    scale = aligned_eye_distance / eye_distance\n",
    "\n",
    "    eyes_center = ((left_eye_center[0,0] + right_eye_center[0,0]) // 2,\n",
    "            (left_eye_center[0,1] + right_eye_center[0,1]) // 2)\n",
    "    cv2.circle(image, eyes_center, 5, (255, 0, 0), -1)\n",
    "            \n",
    "    metrix = cv2.getRotationMatrix2D(eyes_center, degree, scale)\n",
    "    cv2.putText(image, \"{:.5f}\".format(degree), (right_eye_center[0,0], right_eye_center[0,1] + 20),\n",
    "     \t cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    warped = cv2.warpAffine(image_origin, metrix, (image_width, image_height),\n",
    "        flags=cv2.INTER_CUBIC)\n",
    "    \n",
    "    cv2.imshow(\"warpAffine\", warped)\n",
    "    (startX, endX, startY, endY) = getCropDimension(rect, eyes_center)\n",
    "    croped = warped[startY:endY, startX:endX]\n",
    "    output = cv2.resize(croped, OUTPUT_SIZE)\n",
    "    cv2.imshow(\"output\", output)\n",
    "\n",
    "    for (i, point) in enumerate(show_parts):\n",
    "        x = point[0,0]\n",
    "        y = point[0,1]\n",
    "        cv2.circle(image, (x, y), 1, (0, 255, 255), -1)\n",
    "\n",
    "cv2.imshow(\"Face Alignment\", image)\n",
    "cv2.waitKey(0)   \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c7f47-e688-4329-b03d-f2887bba1b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
